# -*- coding: utf-8 -*-
"""Electrical_Fault_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V7VGBey61bnl_LV5vOVAoUCYHPcC7mYc

# **This file contains the dataset to classify the types of fault.**

# **Inputs - [Ia,Ib,Ic,Va,Vb,Vc]**
Ia = Current in line A

Ib = Current in line B

Ic = Current in line C

Va = Voltage in line A

Vb = Voltage in line B

Vc = Voltage in line C

# **Output: [G C B A]**

[0 0 0 0] - No Fault

[1 0 0 1] - LG fault (Between Phase A and Ground)

[0 0 1 1] - LL fault (Between Phase A and Phase B)

[1 0 1 1] - LLG Fault (Between Phases A,B and Ground)

[0 1 1 1] - LLL Fault (Between all three phases)

[1 1 1 1] - LLLG fault (Three phase symmetrical fault)

Here, we conclude that there are 6 types of faults, hence 6 output classes.

# **Importing Libraries**
"""

# Commented out IPython magic to ensure Python compatibility.
''' Install these Libraries
pip install pandas
pip install numpy
pip install scikit-learn
pip install matplotlib
pip install seaborn
pip install jinja2
from IPython.display import clear_output
!pip3 install -U lazypredict
'''
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import matplotlib
import warnings
warnings.filterwarnings('ignore')
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_classification
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import time
from tabulate import tabulate

# Load the dataset
df = pd.read_csv('classData.csv')
# Display the first few rows of the dataset
print("First few rows of the dataset:")
df.head()

# Check Dataframe information
print('--- Dataframe information ---\n')
df.info()

# Null Data in every column
print('---  Null Data in DataFrame of every column ---\n')
print(df.isnull().sum())
# Total Null values in Dataset
print('\n--- Total Null values in DataFrame ---\n')
df.isnull().sum().sum()

# Check Duplicate data in all DataFrame
print("Number Of duplicates:",(df.duplicated().sum()))

# Check total rows and Columns in data frame
print("Total number of rows and columns")
df.shape

# Numeric features
print("The reason why the standard deviation is so big is negative values. It increases the variance of the values significantly.\n")
df.iloc[:, :-1].describe().T.sort_values(by='std' , ascending = False)\
                     .style.background_gradient(cmap='rainbow')\
                     .bar(subset=["max"], color='red')\
                     .bar(subset=["mean",], color='blue')

# Correlation matrix

print("\nCorrelation Matrix:")
features = ['Ia', 'Ib', 'Ic', 'Va', 'Vb', 'Vc']
correlation_matrix = df[features].corr()
print(correlation_matrix)

# Heatmap of the correlation matrix
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix')
plt.show()

no_faults = ((df["G"] == 0) & (df["C"] == 0) & (df["B"] == 0) & (df["B"] == 0)).value_counts()
no_faults_df = pd.DataFrame(no_faults)
no_faults_df = no_faults_df.rename(columns = {"count":"Count"})
print(no_faults_df)
cmap = ["#3274a1", "#e1812c", "#3a923a", "#c03d3e", "#857aab", "#8d7866"]
plt.figure(figsize = (4, 4))
plt.bar(x = no_faults_df.index.to_list(),
        height = no_faults_df.Count,
        label = ["Faulty", "notFaulty"],
        color = cmap)
plt.xlabel("Detection")
plt.ylabel("Number")
plt.title("General Fault Count")
plt.xticks(no_faults_df.index.to_list())
plt.yticks(np.arange(0, 6001, 1000))
plt.legend(bbox_to_anchor = (1, 1), loc = "best")
plt.show();

ax = plt.subplot(1,2,1)
ax = sns.countplot(x='G', data=df)
ax.bar_label(ax.containers[0])
plt.title("Ground Fault", fontsize=20,color = 'Brown',pad=20)

ax =plt.subplot(1,2,2)
ax=df['G'].value_counts().plot.pie(explode=[0.1, 0.1],autopct='%1.2f%%',shadow=True);
ax.set_title(label = "Ground Fault", fontsize = 20,color='Brown',pad=20);

ax = plt.subplot(1,2,1)
ax = sns.countplot(x='A', data=df)
ax.bar_label(ax.containers[0])
plt.title("Line A Fault", fontsize=20,color = 'Brown',pad=20)

ax =plt.subplot(1,2,2)
ax=df['A'].value_counts().plot.pie(explode=[0.1, 0.1],autopct='%1.2f%%',shadow=True);
ax.set_title(label = "Line A Fault", fontsize = 20,color='Brown',pad=20);

ax = plt.subplot(1,2,1)
ax = sns.countplot(x='B', data=df)
ax.bar_label(ax.containers[0])
plt.title("Line B Fault", fontsize=20,color = 'Brown',pad=20)

ax =plt.subplot(1,2,2)
ax=df['B'].value_counts().plot.pie(explode=[0.1, 0.1],autopct='%1.2f%%',shadow=True);
ax.set_title(label = "Line B Fault", fontsize = 20,color='Brown',pad=20);

ax = plt.subplot(1,2,1)
ax = sns.countplot(x='C', data=df)
ax.bar_label(ax.containers[0])
plt.title("Line C Fault", fontsize=20,color = 'Brown',pad=20)

ax =plt.subplot(1,2,2)
ax=df['C'].value_counts().plot.pie(explode=[0.1, 0.1],autopct='%1.2f%%',shadow=True);
ax.set_title(label = "Line C Fault", fontsize = 20,color='Brown',pad=20);

"""# **Combing all fault together in one Fault_Type**"""

print("Combing all fault together in one Fault_Type\n")
df['Fault_Type'] = df['G'].astype('str') + df['C'].astype('str') + df['B'].astype('str') + df['A'].astype('str')
df.head().style.set_properties(**{'background-color': 'green',
                           'color': 'white',
                           'border-color': 'darkblack'})

"""# **Giving the proper name to the fault according to the data description provided above**"""

print("Giving the proper name to the fault according to the data\n")
df['Fault_Type'][df['Fault_Type'] == '0000' ] = 'NO Fault'
df['Fault_Type'][df['Fault_Type'] == '1001' ] = 'Line A to Ground Fault'
df['Fault_Type'][df['Fault_Type'] == '0110' ] = 'Line B to Line C Fault'
df['Fault_Type'][df['Fault_Type'] == '1011' ] = 'Line A Line B to Ground Fault'
df['Fault_Type'][df['Fault_Type'] == '0111' ] = 'Line A Line B Line C'
df['Fault_Type'][df['Fault_Type'] == '1111' ] = 'Line A Line B Line C to Ground Fault'
df.sample(10).style.set_properties(**{'background-color': 'blue',
                           'color': 'white',
                           'border-color': 'darkblack'})

total_fault_types = len(df['Fault_Type'].unique())
print("Total Fault Types:", total_fault_types)
df['Fault_Type'].value_counts(ascending=False)

"""# **Number of faults in the system according to their Fault_Type**"""

ax = plt.figure(figsize = (8,8))
ax = plt.subplot(2,1,1)
ax = sns.countplot(x='Fault_Type', data=df)
ax.bar_label(ax.containers[0])
plt.title("Fault Type", fontsize=20,color = 'Brown',pad=20)
plt.xticks(rotation=65)
plt.tight_layout()
ax =plt.subplot(2,1,2)
ax=df['Fault_Type'].value_counts().plot.pie(explode=[0.1, 0.1,0.1,0.1, 0.1,0.1],autopct='%1.2f%%',shadow=True);
plt.tight_layout()
plt.axis('off');

print("Current graph has large fluctuation therefore fault occured.\n")
plt.figure(figsize = (10,3))
plt.plot(df["Ia"] ,'r' ,label='Ia')
plt.plot(df["Ib"] ,'b' ,label='Ib')
plt.plot(df["Ic"] ,'y' ,label='Ic')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Current graph has large fluctuation")

print("Voltage graph has large fluctuation therefore fault occured.\n")
plt.figure(figsize = (10,3))
plt.plot(df["Va"] ,'r' ,label='Va')
plt.plot(df["Vb"] ,'b' ,label='Vb')
plt.plot(df["Vc"] ,'y' ,label='Vc')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Voltage graph has large fluctuation")

plt.figure(figsize= (15,10))
#Histograms
plt.subplot(3,3,1)
sns.distplot(df['Va'], rug = True, kde = False)
plt.xlabel('Voltage in Per Unit(pu)', fontsize = 12)
plt.title('Distribution of Voltage',fontsize = 15)

plt.subplot(3,3,2)
sns.distplot(df['Ia'], color= 'green',rug = True, kde = False)
plt.title('Distribution of Load of Line',fontsize = 15)
plt.xlabel('Load on line in Amperes', fontsize = 12)


#Kde Plots
plt.subplot(3,3,4)
sns.kdeplot(df['Va'], shade = True)
plt.xlabel('Voltage in Per Unit(pu)', fontsize = 12)
plt.title('Distribution of Voltage',fontsize = 15)

plt.subplot(3,3,5)
sns.kdeplot(df['Ia'], shade = True, color = 'g')
plt.title('Distribution of Load of Line',fontsize = 15)
plt.xlabel('Load on line in Amperes', fontsize = 12)


#Box Plots
plt.subplot(3,3,7)
sns.boxplot(x = df['Va'], orient = 'v',color= 'b', boxprops=dict(alpha=.5))
plt.subplot(3,3,8)
sns.boxplot(x = df['Ia'], orient = 'v', color= 'g', boxprops=dict(alpha=.5))


plt.tight_layout()
plt.show()

"""# **Data Procesing**
## **Separating Faults into different Categories**

# 1. No Fault (Healthy System)
"""

No_Fault = df[df['Fault_Type'] == 'NO Fault' ]
No_Fault.sample(5).style.set_properties(**{'background-color': 'blue',
                           'color': 'white',
                           'border-color': 'darkblack'})

ax = plt.figure(figsize = (10,3))
ax = plt.plot(No_Fault["Ia"],'r', label='Ia')
ax = plt.plot(No_Fault["Ib"],'b', label='Ib')
ax = plt.plot(No_Fault["Ic"],'y', label='Ic');
plt.legend(loc='center left', bbox_to_anchor=(1,0.5), prop={'weight': 'bold'})
plt.title("Current graph is symmetrical at No_Fault ")

ax = plt.figure(figsize = (10,3))
ax = plt.plot(No_Fault["Va"],'r', label='Va')
ax = plt.plot(No_Fault["Vb"],'b', label='Vb')
ax = plt.plot(No_Fault["Vc"],'y', label='Vc');
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Voltage graph is symmetrical at No_Fault ")

"""# **2. Faulty System with Line A to Ground Fault**"""

print("Faulty System with Line A to Ground Fault")
Line_AG_Fault = df[df['Fault_Type'] == 'Line A to Ground Fault' ]
Line_AG_Fault.sample(5).style.set_properties(**{'background-color': 'brown',
                           'color': 'white',
                           'border-color': 'darkblack'})

ax = plt.figure(figsize = (5,3))
ax = plt.plot(Line_AG_Fault["Ia"],'r', label='Ia')
ax = plt.plot(Line_AG_Fault["Ib"],'b', label='Ib')
ax = plt.plot(Line_AG_Fault["Ic"],'y', label='Ic')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Current Graph of Line_AG_Fault")

ax = plt.figure(figsize = (5,5))
ax = plt.plot(Line_AG_Fault["Va"],'r', label='Va')
ax = plt.plot(Line_AG_Fault["Vb"],'b', label='Vb')
ax = plt.plot(Line_AG_Fault["Vc"],'y' ,label='Vc')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Voltage Graph of Line_AG_Fault")

"""# **3. Faulty System with Line A ,Line B to Ground Fault**"""

Line_ABG_Fault = df[df['Fault_Type'] == 'Line A Line B to Ground Fault' ]
Line_ABG_Fault.head().style.set_properties(**{'background-color': 'brown',
                           'color': 'white',
                           'border-color': 'darkblack'})

plt.figure(figsize=(5, 3))
plt.plot(Line_ABG_Fault["Ia"], 'r', label='Ia')
plt.plot(Line_ABG_Fault["Ib"], 'b', label='Ib')
plt.plot(Line_ABG_Fault["Ic"], 'y', label='Ic')
plt.title("Current Graph Line_ABG_Fault")
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.show()

ax = plt.figure(figsize = (5,3))
ax = plt.plot(Line_ABG_Fault["Va"],'r', label='Va')
ax = plt.plot(Line_ABG_Fault["Vb"],'b', label='Vb')
ax = plt.plot(Line_ABG_Fault["Vc"],'y', label='Vc')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Voltage Graph Line_ABG_Fault")

"""# **4. Faulty System with Line B to Line C**"""

Line_BC_Fault = df[df['Fault_Type'] == 'Line B to Line C Fault' ]
Line_BC_Fault.head().style.set_properties(**{'background-color': 'brown',
                           'color': 'white',
                           'border-color': 'darkblack'})

ax = plt.figure(figsize = (5,3))
ax = plt.plot(Line_BC_Fault["Ia"],'r', label='Ia')
ax = plt.plot(Line_BC_Fault["Ib"],'b', label='Ib')
ax = plt.plot(Line_BC_Fault["Ic"],'y', label='Ic');
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Current Graph Line_BC_Fault")

ax = plt.figure(figsize = (5,3))
ax = plt.plot(Line_BC_Fault["Va"],'r', label='Va')
ax = plt.plot(Line_BC_Fault["Vb"],'b', label='Vb')
ax = plt.plot(Line_BC_Fault["Vc"],'y', label='Vc');
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Volatge Graph Line_BC_Fault")

"""# 5. Faulty System with Line A - Line B - Line **C**"""

Line_ABC_Fault = df[df['Fault_Type'] == 'Line A Line B Line C' ]
Line_ABC_Fault.head().style.set_properties(**{'background-color': 'brown',
                           'color': 'white',
                           'border-color': 'darkblack'})

ax = plt.figure(figsize = (5,3))
ax = plt.plot(Line_ABC_Fault["Ia"],'r', label ='Ia')
ax = plt.plot(Line_ABC_Fault["Ib"],'b', label ='Ib')
ax = plt.plot(Line_ABC_Fault["Ic"],'y', label ='Ic')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Current Graph Line_ABC_Fault")

ax = plt.figure(figsize = (5,3))
ax = plt.plot(Line_ABC_Fault["Va"],'r', label ='Va')
ax = plt.plot(Line_ABC_Fault["Vb"],'b', label ='Vb')
ax = plt.plot(Line_ABC_Fault["Vc"],'y', label ='Vc')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Voltage Graph Line_ABC_Fault")

"""# 6. Faulty System with Line A - Line B - Line C - **Ground**"""

Line_ABCG_Fault = df[df['Fault_Type'] == 'Line A Line B Line C to Ground Fault' ]
Line_ABCG_Fault.head().style.set_properties(**{'background-color': 'brown',
                           'color': 'white',
                           'border-color': 'darkblack'})

ax = plt.figure(figsize = (10,3))
ax = plt.plot(Line_ABCG_Fault["Ia"],'r', label ='Ia')
ax = plt.plot(Line_ABCG_Fault["Ib"],'b', label ='Ib')
ax = plt.plot(Line_ABCG_Fault["Ic"],'y', label ='Ic')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Current Graph Line_ABCG_Fault")

ax = plt.figure(figsize = (10,3))
ax = plt.plot(Line_ABCG_Fault["Va"],'r', label ='Va')
ax = plt.plot(Line_ABCG_Fault["Vb"],'b', label ='Vb')
ax = plt.plot(Line_ABCG_Fault["Vc"],'y', label ='Vc')
plt.legend(loc='center left', bbox_to_anchor=(1, 0.5), prop={'weight': 'bold'})
plt.title("Voltage Graph Line_ABCG_Fault")

plt.figure(figsize= (15,10))
#plt.suptitle("Distributions of Different Features", fontsize = 20)
#Histograms
plt.subplot(3,3,1)
sns.distplot(Line_ABCG_Fault['Va'], rug = True, kde = False)
plt.xlabel('Voltage in Per Unit(pu)', fontsize = 12)
plt.title('Distribution of Voltage',fontsize = 15)

plt.subplot(3,3,2)
sns.distplot(Line_ABCG_Fault['Ia'], color= 'green',rug = True, kde = False)
plt.title('Distribution of Load of Line',fontsize = 15)
plt.xlabel('Load on line in Amperes', fontsize = 12)


#Kde Plots
plt.subplot(3,3,4)
sns.kdeplot(Line_ABCG_Fault['Va'], shade = True)
plt.xlabel('Voltage in Per Unit(pu)', fontsize = 12)
plt.title('Distribution of Voltage',fontsize = 15)

plt.subplot(3,3,5)
sns.kdeplot(Line_ABCG_Fault['Ia'], shade = True, color = 'g')
plt.title('Distribution of Load of Line',fontsize = 15)
plt.xlabel('Load on line in Amperes', fontsize = 12)


#Box Plots
plt.subplot(3,3,7)
sns.boxplot(x = Line_ABCG_Fault['Va'], orient = 'v',color= 'b', boxprops=dict(alpha=.5))
plt.subplot(3,3,8)
sns.boxplot(x = Line_ABCG_Fault['Ia'], orient = 'v', color= 'g', boxprops=dict(alpha=.5))


plt.tight_layout()
plt.show()

"""  # **Feature and Label seperation**
# Categorical to Numerical conversion
"""

# Define the custom mapping of fault types to numerical labels
fault_mapping = {
    'NO Fault': 0,
    'Line A to Ground Fault': 1,
    'Line B to Line C Fault': 2,
    'Line A Line B to Ground Fault': 3,
    'Line A Line B Line C': 4,
    'Line A Line B Line C to Ground Fault': 5
}

# Map fault types to numerical labels using the custom mapping
df['Fault_Type_Encoded'] = df['Fault_Type'].map(fault_mapping)

# Display the DataFrame with encoded fault types
print(df[['Fault_Type', 'Fault_Type_Encoded']].sample(10))

from sklearn.preprocessing import StandardScaler

# Scaling Data
scaler = StandardScaler()

# Convert all columns to numeric
X = df.drop(['Fault_Type', 'A', 'B', 'C', 'G', 'Fault_Type_Encoded'], axis=1)
y = df['Fault_Type']

scaled_data = scaler.fit_transform(X)

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(scaled_data, y, test_size=0.2, random_state=123)

print("X Train : ", X_train.shape)
print("X Test  : ", X_test.shape)
print("Y Train : ", y_train.shape)
print("Y Test  : ", y_test.shape)

X = df.drop(['Fault_Type','A','B','C','G','Fault_Type_Encoded'], axis=1)
y = df['Fault_Type']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.20,random_state=21)

"""# **Model Selection**
1. Logistic Regression
2. Naive Byes
3. Decision Tree
4. Random Forest
5. Support Vector Machine

"""

# Assuming you have defined X and y
# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train different models
# Logistic Regression
lr = LogisticRegression()
lr.fit(X_train, y_train)
lr_train_accuracy = round(lr.score(X_train, y_train) * 100, 2)
lr_test_accuracy = round(lr.score(X_test, y_test) * 100, 2)
lr_report = classification_report(y_test, lr.predict(X_test))

# Support Vector Machines (SVM)
svm_classifier = SVC()
svm_classifier.fit(X_train, y_train)
svm_train_accuracy = round(svm_classifier.score(X_train, y_train) * 100, 2)
svm_test_accuracy = round(svm_classifier.score(X_test, y_test) * 100, 2)
svm_report = classification_report(y_test, svm_classifier.predict(X_test))

# Naive Bayes
nb_classifier = GaussianNB()
nb_classifier.fit(X_train, y_train)
nb_train_accuracy = round(nb_classifier.score(X_train, y_train) * 100, 2)
nb_test_accuracy = round(nb_classifier.score(X_test, y_test) * 100, 2)
nb_report = classification_report(y_test, nb_classifier.predict(X_test))

# Decision Tree
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, y_train)
decision_train_accuracy = round(decision_tree.score(X_train, y_train) * 100, 2)
decision_test_accuracy = round(decision_tree.score(X_test, y_test) * 100, 2)
decision_report = classification_report(y_test, decision_tree.predict(X_test))

# Random Forest
random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)
random_forest_train_accuracy = round(random_forest.score(X_train, y_train) * 100, 2)
random_forest_test_accuracy = round(random_forest.score(X_test, y_test) * 100, 2)
random_forest_report = classification_report(y_test, random_forest.predict(X_test))

# Create a DataFrame for model performance
models_performance = pd.DataFrame({
    'Model': ['Logistic Regression', 'Support Vector Machines', 'Naive Bayes', 'Decision Tree', 'Random Forest'],
    'Training Accuracy': [lr_train_accuracy, svm_train_accuracy, nb_train_accuracy, decision_train_accuracy, random_forest_train_accuracy],
    'Testing Accuracy': [lr_test_accuracy, svm_test_accuracy, nb_test_accuracy, decision_test_accuracy, random_forest_test_accuracy],
    'Classification Report': [lr_report, svm_report, nb_report, decision_report, random_forest_report]
})
# Define a function to calculate metrics and time
def calculate_metrics(model, X_train, y_train, X_test, y_test):
    start_time = time.time()
    model.fit(X_train, y_train)
    train_time = time.time() - start_time

    start_time = time.time()
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    predict_time = time.time() - start_time

    train_accuracy = round(accuracy_score(y_train, y_train_pred) * 100, 2)
    test_accuracy = round(accuracy_score(y_test, y_test_pred) * 100, 2)

    precision = round(precision_score(y_test, y_test_pred, average='weighted') * 100, 2)
    recall = round(recall_score(y_test, y_test_pred, average='weighted') * 100, 2)
    f1 = round(f1_score(y_test, y_test_pred, average='weighted') * 100, 2)

    return train_accuracy, test_accuracy, precision, recall, f1, train_time, predict_time

# Train different models and calculate metrics
model_names = ['Logistic Regression', 'Support Vector Machines', 'Naive Bayes', 'Decision Tree', 'Random Forest']
models = [LogisticRegression(), SVC(), GaussianNB(), DecisionTreeClassifier(), RandomForestClassifier()]
metrics = []

for name, model in zip(model_names, models):
    train_acc, test_acc, precision, recall, f1, train_time, predict_time = calculate_metrics(model, X_train, y_train, X_test, y_test)
    metrics.append({
        'Model': name,
        'Training Accuracy': train_acc,
        'Testing Accuracy': test_acc,
        'Precision': precision,
        'Recall': recall,
        'F1-score': f1,
        'Training Time': train_time,
        'Prediction Time': predict_time
    })

# Convert metrics to DataFrame
metrics_df = pd.DataFrame(metrics)
# Display metrics
print("Model Training Selection")
print(tabulate(metrics_df, headers='keys', tablefmt='pretty'))

"""# **Result Prediction**
# 1. Random Forest Classifier
"""

prediction1 = random_forest.predict(X_test)
cross_checking = pd.DataFrame({'Actual' : y_test , 'Predicted' : prediction1})
cross_checking.sample(5).style.background_gradient(
        cmap='coolwarm').set_properties(**{
            'font-family': 'Lucida Calligraphy',
            'color': 'LigntGreen',
            'font-size': '15px'
        })

"""# **2. Decision Tree Classifier**"""

prediction2 = decision.predict(X_test)
cross_checking = pd.DataFrame({'Actual' : y_test , 'Predicted' : prediction2})
cross_checking.sample(5).style.background_gradient(
        cmap='coolwarm').set_properties(**{
            'font-family': 'Lucida Calligraphy',
            'color': 'LigntGreen',
            'font-size': '15px'
        })

"""# **3. Support Vector Machines**"""

prediction3 = svc.predict(X_test)
cross_checking = pd.DataFrame({'Actual' : y_test , 'Predicted' : prediction3})
cross_checking.sample(5).style.background_gradient(
        cmap='coolwarm').set_properties(**{
            'font-family': 'Lucida Calligraphy',
            'color': 'LigntGreen',
            'font-size': '15px'
        })

"""# **4. Logistic Regression**"""

prediction4 = lr.predict(X_test)
cross_checking = pd.DataFrame({'Actual' : y_test , 'Predicted' : prediction4})
cross_checking.sample(5).style.background_gradient(
        cmap='coolwarm').set_properties(**{
            'font-family': 'Lucida Calligraphy',
            'color': 'LigntGreen',
            'font-size': '15px'
        })

"""# **5. Naive Bayes**"""

prediction5 = nb_classifier.predict(X_test)
cross_checking = pd.DataFrame({'Actual' : y_test , 'Predicted' : prediction5})
cross_checking.sample(5).style.background_gradient(
        cmap='coolwarm').set_properties(**{
            'font-family': 'Lucida Calligraphy',
            'color': 'LigntGreen',
            'font-size': '15px'
        })

"""# **Random Forest,Decision Tree Classifier,Naive bayes Classifier, are giving the best Result with 100 percent accuracy and is doing a great job till now in Fault Detection, than the rest of the models because it's able to predict all the signals in most efficient manner while in other models there are cases where there is actually fault but the model is not able to identify it.Logistic Regression is giving the worst accuracy**

# **Classification Model**
"""

from IPython.display import clear_output
!pip3 install -U lazypredict

clear_output()

from lazypredict.Supervised import LazyClassifier
# LazyClassifier
clf = LazyClassifier(verbose=0,
                     ignore_warnings=True,
                     custom_metric=None,
                     predictions=False,
                     random_state=123,
                     classifiers='all')

models, predictions = clf.fit(X_train , X_test , y_train , y_test)
clear_output()
models

"""# **Choose the best-performing algorithm based on evaluation metrics (such as accuracy, precision, recall, F1-score) on the testing set.**

# The final model on the testing set and report the performance metrics
I am choosing Decision Tree as my final model:

# **Inputs:**

Ia: Current in line A

Ib: Current in line B

Ic: Current in line C

Va: Voltage in line A

Vb: Voltage in line B

Vc: Voltage in line C

# Outputs:

[G C B A]

Examples:

[0 0 0 0] - No Fault

[1 0 0 1] - LG fault (Between Phase A and Ground)

[0 1 1 0] - LL fault (Between Phase B and Phase C)

[1 0 1 1] - LLG Fault (Between Phases A, B and Ground)

[0 1 1 1] - LLL Fault (Between all three phases)

[1 1 1 1] - LLLG fault (Three phase symmetrical fault
"""

from sklearn.tree import DecisionTreeClassifier
# Assuming you have defined X and y
X = df.drop(['Fault_Type', 'A', 'B', 'C', 'G', 'Fault_Type_Encoded'], axis=1)
y = df['Fault_Type']

# Train a Decision Tree classifier
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X, y)

# Take input from the user for voltage and current values
user_input = {}
try:
    user_input['Va'] = float(input("Enter Voltage(Va): "))
    user_input['Vb'] = float(input("Enter Voltage(Vb): "))
    user_input['Vc'] = float(input("Enter Voltage(Vc): "))
    user_input['Ia'] = float(input("Enter Current(Ia): "))
    user_input['Ib'] = float(input("Enter Current(Ib): "))
    user_input['Ic'] = float(input("Enter Current(Ic): "))
except ValueError:
    print("Please enter valid numeric values for voltage and current.")
    exit()

# Create a DataFrame with user input
user_data = pd.DataFrame([user_input])

# Ensure that the user_data columns match the training features and order
user_data = user_data[X.columns]

# Make a prediction based on user input
user_prediction = clf.predict(user_data)

# Display the predicted fault type with proper names
fault_names = {
    0: 'NO Fault',
    1: 'Line A to Ground Fault',
    2: 'Line B to Line C Fault',
    3: 'Line A Line B to Ground Fault',
    4: 'Line A Line B Line C',
    5: 'Line A Line B Line C to Ground Fault'
}
# Print the predicted label
print("-----------------------------------------\n")
print("\nBased on the user input, the Fault Analysis predicts", user_prediction[0])